{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0538fe5d-3f38-4396-921c-58069f2c61f6",
   "metadata": {},
   "source": [
    "### í—ˆê¹…í˜ì´ìŠ¤ë¡œ ì¸í¼ëŸ°ìŠ¤í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dbeb9-c586-489c-90f6-b2cb156aa60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nvidia-smi\n",
    "#pip install vllm\n",
    "#pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec7774-a38c-407e-8610-a06a023c3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c45e69-ebe5-4599-b2be-054525abf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your prompt\n",
    "prompt = \"Explain how wonderful you are\"  # English example\n",
    "prompt = \"ìŠ¤ìŠ¤ë¡œë¥¼ ìë‘í•´ ë´\"       # Korean example\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b62556-9625-4546-8ddc-a0340c69eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ede4b-69a2-4b5d-ae25-2380a8edac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(input_ids.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77485123-76da-4371-ba76-cda649789c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91bfb2-86f0-4662-adbc-5065c427b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer.decode([torch.argmax(o.logits[:,-1,:]).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7e735-a681-4415-ade7-043b45ea0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    input_ids.to(\"cuda\"),\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    ")\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8f3ad-3ac9-47e4-aa8a-3ed072ca1e5c",
   "metadata": {},
   "source": [
    "### VLLMìœ¼ë¡œ ì¸í¼ëŸ°ìŠ¤í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba286d9a-f0ef-4ee5-96cf-61e538c12447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "\n",
    "# https://docs.vllm.ai/en/v0.7.2/getting_started/quickstart.html\n",
    "# https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\n",
    "\n",
    "model_name = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\"\n",
    "llm = LLM(model=model_name, tensor_parallel_size=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e785949-4275-464c-a098-a3c144061d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature=0.8: ëª¨ë¸ ì¶œë ¥ì˜ ë¬´ì‘ìœ„ì„±ì„ ì œì–´í•˜ë©°, ë‚®ì„ìˆ˜ë¡ ê²°ì •ë¡ ì ì´ê³  ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘ì„±ì´ ì¦ê°€í•©ë‹ˆë‹¤.\n",
    "# top_p=0.95: ëˆ„ì  í™•ë¥ ì´ 0.95ê°€ ë  ë•Œê¹Œì§€ ìƒìœ„ í† í° í›„ë³´ë¥¼ ëª¨ì•„ ê·¸ì¤‘ì—ì„œ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.\n",
    "# min_tokens=8: ìµœì†Œ 8ê°œì˜ í† í°ì€ ë°˜ë“œì‹œ ìƒì„±í•˜ë„ë¡ ê°•ì œí•˜ì—¬, ì§§ê²Œ ëë‚˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n",
    "# max_tokens=512: ìµœëŒ€ 512ê°œì˜ í† í°ê¹Œì§€ë§Œ ìƒì„±í•˜ë©°, í•´ë‹¹ ìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì¶œë ¥ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
    "# repetition_penalty (ì˜ˆ: 1.2): ì´ë¯¸ ìƒì„±ëœ í† í°ì˜ ë°˜ë³µì„ ì–µì œí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ë©°, 1.0ë³´ë‹¤ í´ìˆ˜ë¡ ë°˜ë³µì´ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, min_tokens=8, max_tokens=512) #repetition_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96c016-7f10-44b7-adc4-90baf141f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"ì ì‹¬ì„ ë­˜ ë¨¹ì„ê¹Œ?\",\n",
    "    \"í‡´ê·¼í•˜ê³  ì‹¶ì€ë° ê°€ë„ ë ê¹Œ?\"\n",
    "]\n",
    "tokenizer = llm.get_tokenizer()\n",
    "\n",
    "qrys = []\n",
    "for p in prompts:\n",
    "    chat = [\n",
    "            {\"role\": \"tool_list\", \"content\": \"\"},\n",
    "            {\"role\": \"system\", \"content\": \"- AI ì–¸ì–´ëª¨ë¸ì˜ ì´ë¦„ì€ \\\"CLOVA X\\\" ì´ë©° ë„¤ì´ë²„ì—ì„œ ë§Œë“¤ì—ˆë‹¤.\\n- ì˜¤ëŠ˜ì€ 2025ë…„ 04ì›” 24ì¼(ëª©)ì´ë‹¤.\"},\n",
    "            {\"role\": \"user\", \"content\": p},\n",
    "        ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(chat, add_generation_prompt=True,tokenize=False)\n",
    "    qrys.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacfb14-9929-46d6-a25b-b51bd2fbc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = llm.generate(qrys, sampling_params)\n",
    "outputs = [output.outputs[0].text for output in outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe9346-17ca-4622-b0d8-4b50399b8102",
   "metadata": {},
   "source": [
    "### VLLM ìœ¼ë¡œ ì„œë¹™í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03e07d-b9aa-40c5-a8d2-16b3fde61e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html\n",
    "\n",
    "vllm serve naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B \\\n",
    "  --dtype auto \\\n",
    "  --api-key token-abc123\n",
    "  --port 1210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd5517-623d-49c8-814f-317996da3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1210/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5012a5-4b26-4c55-af89-6b0109366df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì¸ì‚¬ë¥¼ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n1. **ì•ˆë…•í•˜ì„¸ìš”**\\n- ê°€ì¥ ê¸°ë³¸ì ì¸ ì¸ì‚¬ë§ì…ë‹ˆë‹¤. \"ì•ˆë…•í•˜ì„¸ìš”\" ë˜ëŠ” \"ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ\" ë“±ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. **ë°˜ê°‘ìŠµë‹ˆë‹¤**\\n- ìƒëŒ€ë°©ì—ê²Œ ë°˜ê°‘ë‹¤ëŠ” ì¸ì‚¬ë¥¼ ì „í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n3. **ì˜ ì§€ë‚´ê³  ìˆë‚˜ìš”?**\\n- ìƒëŒ€ë°©ì˜ ì•ˆë¶€ë¥¼ ë¬»ëŠ” ì¸ì‚¬ë§ì…ë‹ˆë‹¤. \"ì˜ ì§€ë‚´ê³  ìˆë‚˜ìš”?\" í˜¹ì€ \"ì˜ ì§€ë‚´ê³  ê³„ì‹ ê°€ìš”?\" ë“±ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://38.147.83.29:38315/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a8f97-027d-4f4d-b159-a35afb776805",
   "metadata": {},
   "source": [
    "### OpenAI API ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6b1b7a-b783-4049-934a-59ee621e3597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under a blanket of twinkling stars, a gentle unicorn tiptoed through a moonlit meadow, sprinkling dreams of magic and kindness wherever she went.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# https://platform.openai.com/docs/quickstart?api-mode=chat\n",
    "# https://platform.openai.com/docs/models\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62727d09-0623-4d0e-8a03-910ea960141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a scenic view of a boardwalk or pathway leading through a grassy area. There are lush green grasses on either side of the pathway, and the sky above is bright with fluffy clouds. It appears to be a natural landscape, possibly in a wetland or meadow, creating a serene and open atmosphere.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ebc3a1-b088-4c58-8b83-5c6fcdb85b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "def encode_data_uri(path: Union[str, Path]) -> str:\n",
    "    \"\"\"Read a file and return a data URI string.\"\"\"\n",
    "    path = Path(path)  # Ensure we have a Path object\n",
    "    raw = path.read_bytes()\n",
    "    b64 = base64.b64encode(raw).decode(\"ascii\")\n",
    "    mime = mimetypes.guess_type(path.name)[0] or \"application/octet-stream\"\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# Example usage:\n",
    " = encode_data_uri(\"assets/istockphoto-509661920-612x612.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b104984-4020-4e72-aedb-9ed7c687d824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ëŠ” ì „í†µ í•œêµ­ ê±´ì¶•ë¬¼ì´ ìˆëŠ” ì¥ë©´ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê±´ë¬¼ì€ í™”ë ¤í•˜ê²Œ ì¥ì‹ë˜ì–´ ìˆìœ¼ë©°, ì „í†µì ì¸ ì§€ë¶• í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë°°ê²½ì—ëŠ” ì‚°ì´ ìˆì–´ ìì—°ê²½ê´€ê³¼ ì¡°í™”ë¡œìš´ ë¶„ìœ„ê¸°ë¥¼ ìì•„ëƒ…ë‹ˆë‹¤. ì´ ì¥ì†ŒëŠ” ì—­ì‚¬ì  ì˜ë¯¸ê°€ ìˆëŠ” ê³µì›ì´ë‚˜ ê¶ì „ì˜ ì¼ë¶€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©°, ì•„ì¹¨ì´ë‚˜ ì €ë…ì˜ ì°¨ë¶„í•œ ë¶„ìœ„ê¸°ê°€ ëŠê»´ì§‘ë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ê³ í’ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ì„ ì§€ë‹Œ ì¥ë©´ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image? Explain in Korean.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": data_uri,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3f6ab-128e-4d62-8616-dc4ece14f4ec",
   "metadata": {},
   "source": [
    "### OpenRouter API ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bae35-fbed-4bbf-b977-685398b5ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33c9e448-7ad4-4811-a302-4e9cc4aa6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import os\n",
    "from litellm import batch_completion, completion\n",
    "\n",
    "# https://openrouter.ai/models\n",
    "\n",
    "os.environ['OPENROUTER_API_KEY'] = \"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\"\n",
    "\n",
    "\n",
    "response = completion(\n",
    "  model=\"openrouter/deepseek/deepseek-r1-0528-qwen3-8b\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc589ca-d460-484b-937b-32973c1cb7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! ğŸ˜Š  \\nI'm doing wellâ€”just waiting here ready to help you with whatever you need. How are *you* doing today? I'd love to know how I can assist you!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c170e2b-0a3f-4de9-9604-24d9e26776c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, the user greeted me with \"Hello, how are you?\" and asked how I\\'m doing. \\n\\nHmm, this is a pretty casual greeting exchange, one of those typical interactions where users test the waters with polite small talk before diving into more complex topics. \\n\\nLet me analyze this. The user is probably feeling neutral or slightly positive in their mood - not urgent, but not deeply relaxing either. They might be curious about how virtual assistants handle these social niceties. \\n\\nI should respond naturally but keep it warm and inviting. The key is to mirror their tone while gently steering toward more productive conversation. \\n\\nI\\'ll start with the standard \"all systems operational\" bit to convey competence, then pivot to asking how they are doing. Including a smiley face makes this feel more human. The placeholder for their name personalizes it without being too invasive. \\n\\nThis balance feels right - acknowledges the social nicety while keeping the door open for whatever they might actually need help with. The user seems to be gathering their thoughts, so I don\\'t want to pressure them for specific questions right away.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.reasoning_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd827888-7c30-4a68-80fc-da9006f38679",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "  model=\"openrouter/google/gemma-2b-it\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "446ec2fd-001c-4417-bc4b-a826f28d7249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am doing well and thank you for your question. I am functioning properly and ready to assist you with your needs. Is there anything I can help you with today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90574364-d45e-4f88-83ae-d85d86aa30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "  model=\"openrouter/perplexity/sonar-pro\",\n",
    "  messages=[{ \"content\": \"ì†ê·œì§„ì´ ëˆ„êµ¬ì•¼?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad035bd-358e-45f4-aeff-3373c59e8900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì†ê·œì§„(Guijin Son)ì€ ì—°ì„¸ëŒ€í•™êµì—ì„œ ê²½ì œí•™ì„ ì „ê³µí•˜ëŠ” í•™ìƒì´ì ìì—°ì–´ ì²˜ë¦¬(Natural Language Processing) ë¶„ì•¼ì˜ ì—°êµ¬ìì…ë‹ˆë‹¤[1]. ê·¸ëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ê³  ìˆìœ¼ë©°, ë…¼ë¬¸ ì‘ì„±ê³¼ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤[1].\\n\\nì§ì—…ì ìœ¼ë¡œëŠ” ì˜¨ë¼ì¸ AI ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ AI ë¦¬ì„œì¹˜ ì—­í• ì„ ë§¡ê³  ìˆìœ¼ë©°, í•´ì™¸ ë‹¨ì²´ì¸ ì¼ë¡œë“œ AI(ILORED AI)ì—ì„œë„ ë°ì´í„°ì…‹ ì œì‘ ë° ì¸ìŠ¤íŠ¸ëŸ­ì…˜ íŠœë‹ ì—…ë¬´ë¥¼ ë‹´ë‹¹í–ˆë˜ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤[2].\\n\\nì†ê·œì§„ì€ í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì£¼ëª©í•  ë§Œí•œ ì„±ê³¼ë¥¼ ë³´ì—¬ì™”ìŠµë‹ˆë‹¤. íŠ¹íˆ ì½”-í´ë¦½(Ko-CLIP)ì´ë¼ëŠ” í”„ë¡œì íŠ¸ì—ì„œ ì–¸ì–´ ëª¨ë¸ê³¼ ì´ë¯¸ì§€ ëª¨ë¸ì„ ê²°í•©í•œ í´ë¦½(CLIP) ëª¨ë¸ì„ í•œêµ­ì–´ì— ìµœì´ˆë¡œ ì ìš©í–ˆìŠµë‹ˆë‹¤[2]. ë˜í•œ í—¤ë¸-C QAì™€ KMMê³¼ ê°™ì€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ ê°œë°œí•˜ê³  ê³µê°œí•˜ëŠ” í™œë™ì„ ì§€ì†ì ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤[2].\\n\\nê·¸ëŠ” TEDxYonseiUniversityì™€ ëª¨ë‘ì½˜2023 ê°™ì€ í–‰ì‚¬ì—ì„œ ì¸ê³µì§€ëŠ¥ê³¼ ì–¸ì–´ ëª¨ë¸ì— ê´€í•œ ê°•ì—°ì„ ì§„í–‰í•˜ë©°, ì´ ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ì„±ì„ ëŒ€ì¤‘ê³¼ ê³µìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤[1][2].'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "278b5206-793f-4cec-b6b1-9292d9866911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'url_citation',\n",
       "  'url_citation': {'end_index': 0,\n",
       "   'start_index': 0,\n",
       "   'title': 'www.youtube.com/watch',\n",
       "   'url': 'https://www.youtube.com/watch?v=aVDUZEWZecA'}},\n",
       " {'type': 'url_citation',\n",
       "  'url_citation': {'end_index': 0,\n",
       "   'start_index': 0,\n",
       "   'title': 'www.youtube.com/watch',\n",
       "   'url': 'https://www.youtube.com/watch?v=5xqbyZZX2cw'}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f281b91-59f9-4488-b707-08dbc1a86f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "  },\n",
    "  data=json.dumps({\n",
    "    \"model\": \"qwen/qwen3-14b:online\", # Optional\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ì†ê·œì§„ì´ ëˆ„êµ¬ì•¼\"\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a06ebd95-873a-4508-96b3-5e690b18b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì†ê·œì§„(GUIJIN SON)ì€ ì—°ì„¸ëŒ€í•™êµ ì–¸ë”ìš°ë“œêµ­ì œëŒ€í•™ì—ì„œ ê²½ì œí•™ì„ ì „ê³µí•˜ê³  ìˆëŠ” ì—°êµ¬ìë¡œ, ê¸ˆìœµ ë„ë©”ì¸ì˜ ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ê³¼ ìì—°ì–´ ì²˜ë¦¬(NLP) ë¶„ì•¼ì—ì„œ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” íŠ¹íˆ ì–¸ì–´ ëª¨ë¸ì— \"íœ˜ë°œì„± ì§€ì‹\"(ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ì •ë³´)ì´ ê³¼ë„í•˜ê²Œ í•™ìŠµë˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **TGT-Masking**ì´ë¼ëŠ” ë°©ë²•ë¡ ì„ ì œì•ˆí•œ ì—°êµ¬ë¥¼ ì§„í–‰í•œ ë°” ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê¸ˆìœµ ë¶„ì•¼ì˜ ëª¨ë¸ì´ íŠ¹ì • ì‹œì ì˜ ë°ì´í„°ë¡œ í•™ìŠµëœ ê²½ìš°(ì˜ˆ: 2022ë…„ì˜ FOMC ê´€ë ¨ í…ìŠ¤íŠ¸) ì‹œê°„ì´ íë¥¸ í›„(ì˜ˆ: 2024ë…„) ì •í™•í•œ ì˜ˆì¸¡ì„ ëª»í•˜ëŠ” í•œê³„ë¥¼ ê·¹ë³µí•˜ë ¤ëŠ” ëª©ì ì„ ê°€ì¡ŒìŠµë‹ˆë‹¤ [kr.linkedin.com](https://kr.linkedin.com/posts/guijin-son-4909331bb_removing-non-stationary-knowledge-from-pre-trained-activity-7019855625123749888-ZcEu).\n",
      "\n",
      "ë˜í•œ 2024ë…„ì—ëŠ” í•œêµ­ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ **HyperCLOVA X**ì˜ ì„±ëŠ¥ í‰ê°€ ë° ê°œì„ ì— ì°¸ì—¬í–ˆìœ¼ë©°, **HAE-RAE Bench**ì™€ **KMMLU**ì™€ ê°™ì€ í‰ê°€ ê¸°ì¤€ ë§ˆë ¨ì—ë„ ê¸°ì—¬í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ì™€ ê´€ë ¨ëœ ë°œí‘œëŠ” ë­ì²´ì¸ì½”ë¦¬ì•„ ë°‹ì—…ì—ì„œ ì´ë£¨ì–´ì§ˆ ì˜ˆì •ì´ì—ˆìŠµë‹ˆë‹¤ [kr.linkedin.com](https://kr.linkedin.com/posts/guijin-son-4909331bb_lrec-naver-eleutherai-activity-7165924848332910592-m7r4).\n",
      "\n",
      "ê¸°íƒ€ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ 'ì†ì†Œ'ë‚˜ 'ì†ê¸°ì •'ì€ ì†ê·œì§„ê³¼ëŠ” ë³„ê°œì˜ ì¸ë¬¼ë¡œ ë³´ì´ë©°, ë‚˜ë¬´ìœ„í‚¤ì˜ 'ì†ê¸°ì •'ì€ ë‹¬ë¦¬ì–´ëŠ” ì„ ìˆ˜ì™€ ê´€ë ¨ëœ ì¸ë¬¼ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f2508-4f40-431f-8bd9-cc7ea8877eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
