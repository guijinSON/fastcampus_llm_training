{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0538fe5d-3f38-4396-921c-58069f2c61f6",
   "metadata": {},
   "source": [
    "### 허깅페이스로 인퍼런스하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dbeb9-c586-489c-90f6-b2cb156aa60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nvidia-smi\n",
    "#pip install vllm\n",
    "#pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec7774-a38c-407e-8610-a06a023c3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c45e69-ebe5-4599-b2be-054525abf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your prompt\n",
    "prompt = \"Explain how wonderful you are\"  # English example\n",
    "prompt = \"스스로를 자랑해 봐\"       # Korean example\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b62556-9625-4546-8ddc-a0340c69eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ede4b-69a2-4b5d-ae25-2380a8edac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(input_ids.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77485123-76da-4371-ba76-cda649789c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(o.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91bfb2-86f0-4662-adbc-5065c427b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer.decode([torch.argmax(o.logits[:,-1,:]).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c7e735-a681-4415-ade7-043b45ea0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(\n",
    "    input_ids.to(\"cuda\"),\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    ")\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8f3ad-3ac9-47e4-aa8a-3ed072ca1e5c",
   "metadata": {},
   "source": [
    "### VLLM으로 인퍼런스하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba286d9a-f0ef-4ee5-96cf-61e538c12447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "\n",
    "# https://docs.vllm.ai/en/v0.7.2/getting_started/quickstart.html\n",
    "# https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\n",
    "\n",
    "model_name = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\"\n",
    "llm = LLM(model=model_name, tensor_parallel_size=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e785949-4275-464c-a098-a3c144061d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature=0.8: 모델 출력의 무작위성을 제어하며, 낮을수록 결정론적이고 높을수록 다양성이 증가합니다.\n",
    "# top_p=0.95: 누적 확률이 0.95가 될 때까지 상위 토큰 후보를 모아 그중에서 샘플링합니다.\n",
    "# min_tokens=8: 최소 8개의 토큰은 반드시 생성하도록 강제하여, 짧게 끝나지 않도록 합니다.\n",
    "# max_tokens=512: 최대 512개의 토큰까지만 생성하며, 해당 수를 초과하면 출력을 중단합니다.\n",
    "# repetition_penalty (예: 1.2): 이미 생성된 토큰의 반복을 억제하기 위해 사용하며, 1.0보다 클수록 반복이 줄어듭니다.\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, min_tokens=8, max_tokens=512) #repetition_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96c016-7f10-44b7-adc4-90baf141f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"점심을 뭘 먹을까?\",\n",
    "    \"퇴근하고 싶은데 가도 될까?\"\n",
    "]\n",
    "tokenizer = llm.get_tokenizer()\n",
    "\n",
    "qrys = []\n",
    "for p in prompts:\n",
    "    chat = [\n",
    "            {\"role\": \"tool_list\", \"content\": \"\"},\n",
    "            {\"role\": \"system\", \"content\": \"- AI 언어모델의 이름은 \\\"CLOVA X\\\" 이며 네이버에서 만들었다.\\n- 오늘은 2025년 04월 24일(목)이다.\"},\n",
    "            {\"role\": \"user\", \"content\": p},\n",
    "        ]\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(chat, add_generation_prompt=True,tokenize=False)\n",
    "    qrys.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacfb14-9929-46d6-a25b-b51bd2fbc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = llm.generate(qrys, sampling_params)\n",
    "outputs = [output.outputs[0].text for output in outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe9346-17ca-4622-b0d8-4b50399b8102",
   "metadata": {},
   "source": [
    "### VLLM 으로 서빙하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03e07d-b9aa-40c5-a8d2-16b3fde61e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html\n",
    "\n",
    "vllm serve naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B \\\n",
    "  --dtype auto \\\n",
    "  --api-key token-abc123\n",
    "  --port 1210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd5517-623d-49c8-814f-317996da3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1210/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5012a5-4b26-4c55-af89-6b0109366df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='다음과 같은 방법으로 인사를 답변을 할 수 있습니다.\\n\\n1. **안녕하세요**\\n- 가장 기본적인 인사말입니다. \"안녕하세요\" 또는 \"안녕하십니까\" 등으로 표현할 수 있습니다.\\n\\n2. **반갑습니다**\\n- 상대방에게 반갑다는 인사를 전할 때 사용할 수 있습니다.\\n\\n3. **잘 지내고 있나요?**\\n- 상대방의 안부를 묻는 인사말입니다. \"잘 지내고 있나요?\" 혹은 \"잘 지내고 계신가요?\" 등으로 표현할 수 있습니다.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://38.147.83.29:38315/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a8f97-027d-4f4d-b159-a35afb776805",
   "metadata": {},
   "source": [
    "### OpenAI API 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6b1b7a-b783-4049-934a-59ee621e3597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under a blanket of twinkling stars, a gentle unicorn tiptoed through a moonlit meadow, sprinkling dreams of magic and kindness wherever she went.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# https://platform.openai.com/docs/quickstart?api-mode=chat\n",
    "# https://platform.openai.com/docs/models\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62727d09-0623-4d0e-8a03-910ea960141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a scenic view of a boardwalk or pathway leading through a grassy area. There are lush green grasses on either side of the pathway, and the sky above is bright with fluffy clouds. It appears to be a natural landscape, possibly in a wetland or meadow, creating a serene and open atmosphere.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ebc3a1-b088-4c58-8b83-5c6fcdb85b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "def encode_data_uri(path: Union[str, Path]) -> str:\n",
    "    \"\"\"Read a file and return a data URI string.\"\"\"\n",
    "    path = Path(path)  # Ensure we have a Path object\n",
    "    raw = path.read_bytes()\n",
    "    b64 = base64.b64encode(raw).decode(\"ascii\")\n",
    "    mime = mimetypes.guess_type(path.name)[0] or \"application/octet-stream\"\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# Example usage:\n",
    " = encode_data_uri(\"assets/istockphoto-509661920-612x612.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b104984-4020-4e72-aedb-9ed7c687d824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 이미지는 전통 한국 건축물이 있는 장면을 보여주고 있습니다. 건물은 화려하게 장식되어 있으며, 전통적인 지붕 형태를 가지고 있습니다. 배경에는 산이 있어 자연경관과 조화로운 분위기를 자아냅니다. 이 장소는 역사적 의미가 있는 공원이나 궁전의 일부일 가능성이 높으며, 아침이나 저녁의 차분한 분위기가 느껴집니다. 전체적으로 고풍스러운 아름다움을 지닌 장면입니다.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image? Explain in Korean.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": data_uri,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3f6ab-128e-4d62-8616-dc4ece14f4ec",
   "metadata": {},
   "source": [
    "### OpenRouter API 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bae35-fbed-4bbf-b977-685398b5ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33c9e448-7ad4-4811-a302-4e9cc4aa6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import os\n",
    "from litellm import batch_completion, completion\n",
    "\n",
    "# https://openrouter.ai/models\n",
    "\n",
    "os.environ['OPENROUTER_API_KEY'] = \"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\"\n",
    "\n",
    "\n",
    "response = completion(\n",
    "  model=\"openrouter/deepseek/deepseek-r1-0528-qwen3-8b\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc589ca-d460-484b-937b-32973c1cb7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! 😊  \\nI'm doing well—just waiting here ready to help you with whatever you need. How are *you* doing today? I'd love to know how I can assist you!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c170e2b-0a3f-4de9-9604-24d9e26776c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, the user greeted me with \"Hello, how are you?\" and asked how I\\'m doing. \\n\\nHmm, this is a pretty casual greeting exchange, one of those typical interactions where users test the waters with polite small talk before diving into more complex topics. \\n\\nLet me analyze this. The user is probably feeling neutral or slightly positive in their mood - not urgent, but not deeply relaxing either. They might be curious about how virtual assistants handle these social niceties. \\n\\nI should respond naturally but keep it warm and inviting. The key is to mirror their tone while gently steering toward more productive conversation. \\n\\nI\\'ll start with the standard \"all systems operational\" bit to convey competence, then pivot to asking how they are doing. Including a smiley face makes this feel more human. The placeholder for their name personalizes it without being too invasive. \\n\\nThis balance feels right - acknowledges the social nicety while keeping the door open for whatever they might actually need help with. The user seems to be gathering their thoughts, so I don\\'t want to pressure them for specific questions right away.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.reasoning_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd827888-7c30-4a68-80fc-da9006f38679",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "  model=\"openrouter/google/gemma-2b-it\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "446ec2fd-001c-4417-bc4b-a826f28d7249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am doing well and thank you for your question. I am functioning properly and ready to assist you with your needs. Is there anything I can help you with today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90574364-d45e-4f88-83ae-d85d86aa30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "  model=\"openrouter/perplexity/sonar-pro\",\n",
    "  messages=[{ \"content\": \"손규진이 누구야?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad035bd-358e-45f4-aeff-3373c59e8900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'손규진(Guijin Son)은 연세대학교에서 경제학을 전공하는 학생이자 자연어 처리(Natural Language Processing) 분야의 연구자입니다[1]. 그는 언어 모델과 인공지능 관련 연구를 수행하고 있으며, 논문 작성과 오픈소스 프로젝트에 적극적으로 참여하고 있습니다[1].\\n\\n직업적으로는 온라인 AI 스타트업에서 AI 리서치 역할을 맡고 있으며, 해외 단체인 일로드 AI(ILORED AI)에서도 데이터셋 제작 및 인스트럭션 튜닝 업무를 담당했던 경험이 있습니다[2].\\n\\n손규진은 한국어 자연어 처리 분야에서 주목할 만한 성과를 보여왔습니다. 특히 코-클립(Ko-CLIP)이라는 프로젝트에서 언어 모델과 이미지 모델을 결합한 클립(CLIP) 모델을 한국어에 최초로 적용했습니다[2]. 또한 헤븐-C QA와 KMM과 같은 벤치마크 데이터셋을 개발하고 공개하는 활동을 지속적으로 하고 있습니다[2].\\n\\n그는 TEDxYonseiUniversity와 모두콘2023 같은 행사에서 인공지능과 언어 모델에 관한 강연을 진행하며, 이 분야에 대한 전문성을 대중과 공유하고 있습니다[1][2].'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "278b5206-793f-4cec-b6b1-9292d9866911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'url_citation',\n",
       "  'url_citation': {'end_index': 0,\n",
       "   'start_index': 0,\n",
       "   'title': 'www.youtube.com/watch',\n",
       "   'url': 'https://www.youtube.com/watch?v=aVDUZEWZecA'}},\n",
       " {'type': 'url_citation',\n",
       "  'url_citation': {'end_index': 0,\n",
       "   'start_index': 0,\n",
       "   'title': 'www.youtube.com/watch',\n",
       "   'url': 'https://www.youtube.com/watch?v=5xqbyZZX2cw'}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f281b91-59f9-4488-b707-08dbc1a86f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.post(\n",
    "  url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "  headers={\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "  },\n",
    "  data=json.dumps({\n",
    "    \"model\": \"qwen/qwen3-14b:online\", # Optional\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"손규진이 누구야\"\n",
    "      }\n",
    "    ]\n",
    "  })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a06ebd95-873a-4508-96b3-5e690b18b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손규진(GUIJIN SON)은 연세대학교 언더우드국제대학에서 경제학을 전공하고 있는 연구자로, 금융 도메인의 시계열 데이터 분석과 자연어 처리(NLP) 분야에서 활동하고 있습니다. 그는 특히 언어 모델에 \"휘발성 지식\"(시간에 따라 변화하는 정보)이 과도하게 학습되는 문제를 해결하기 위해 **TGT-Masking**이라는 방법론을 제안한 연구를 진행한 바 있습니다. 이 연구는 금융 분야의 모델이 특정 시점의 데이터로 학습된 경우(예: 2022년의 FOMC 관련 텍스트) 시간이 흐른 후(예: 2024년) 정확한 예측을 못하는 한계를 극복하려는 목적을 가졌습니다 [kr.linkedin.com](https://kr.linkedin.com/posts/guijin-son-4909331bb_removing-non-stationary-knowledge-from-pre-trained-activity-7019855625123749888-ZcEu).\n",
      "\n",
      "또한 2024년에는 한국 대규모 언어 모델 **HyperCLOVA X**의 성능 평가 및 개선에 참여했으며, **HAE-RAE Bench**와 **KMMLU**와 같은 평가 기준 마련에도 기여한 것으로 보입니다. 이와 관련된 발표는 랭체인코리아 밋업에서 이루어질 예정이었습니다 [kr.linkedin.com](https://kr.linkedin.com/posts/guijin-son-4909331bb_lrec-naver-eleutherai-activity-7165924848332910592-m7r4).\n",
      "\n",
      "기타 검색 결과 중 '손소'나 '손기정'은 손규진과는 별개의 인물로 보이며, 나무위키의 '손기정'은 달리어는 선수와 관련된 인물입니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f2508-4f40-431f-8bd9-cc7ea8877eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
